{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proccess the video\n",
    "Main part of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # for webcam\n",
    "#cap = cv2.VideoCapture('Videos/front_face.mp4') # For video file\n",
    " \n",
    "face_casc = cv2.CascadeClassifier('HaarCascades/haarcascade_frontalface_default.xml') # detects front face only\n",
    "eye_casc = cv2.CascadeClassifier('HaarCascades/haarcascade_eye.xml') # detects eye\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "        # convert to gray, Because its computationally less expensive and more easy to operate \n",
    "        # haarcascade on grayscale images\n",
    "        \n",
    "        faces = face_casc.detectMultiScale(gray,1.3, 5)\n",
    "        \n",
    "        if faces is ():\n",
    "            cv2.imshow('Face',frame)\n",
    "        else:\n",
    "            for (x,y,w,h) in faces:\n",
    "                img = cv2.rectangle(frame, # image to operate on\n",
    "                                (x,y), # start of the rectangle\n",
    "                                (x+w, y+h), # end of rectangle\n",
    "                                (255, 255, 0), # color of the rectangle\n",
    "                                2) # thickness\n",
    "                \n",
    "                # to detect eye we will work inside the face, cuz we cant find eye outside of this region.\n",
    "                # For that we will slect the face part for the roi(region of interest)\n",
    "                \n",
    "                roi_gray = gray[y:y+h,\n",
    "                                x: x+w]\n",
    "                roi_color = frame[y:y+h,\n",
    "                                  x:x+w] # for the color image part to use on later\n",
    "                \n",
    "                eyes = eye_casc.detectMultiScale(roi_gray,1.3,5)\n",
    "                for (ex,ey,ew,eh) in eyes:\n",
    "                    # draw rectangle for eyes\n",
    "                    cv2.rectangle(roi_color,\n",
    "                                 (ex, ey),\n",
    "                                 (ex+ew, ey+eh),\n",
    "                                 (0,255,0),\n",
    "                                 2)\n",
    "                \n",
    "                cv2.imshow('Face',img)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break;\n",
    "    else:\n",
    "        break;\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "\n",
    "Dont run this part. It's for understanding perpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-a30572bfe784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m the inital value or determine that there is a face in the first frame'''\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mface_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_rects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtrack_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mface_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# get the xml file\n",
    "face_casc = cv2.CascadeClassifier('HaarCascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_rects = face_casc.detectMultiScale(frame,\n",
    "                                        1.3, # How much the quality will be reduced\n",
    "                                        5) # no. of minimum neighbour neighbors\n",
    "\n",
    "''' If there is no face in the first frame then detectMultiScale will return none. Thats why we have to hard code \n",
    "the inital value or determine that there is a face in the first frame'''\n",
    "\n",
    "face_x, face_y, w, h = tuple(face_rects[0])\n",
    "track_window = (face_x, face_y, w, h)\n",
    "\n",
    "roi = frame[face_y:face_y+h,\n",
    "            face_x:face_x+w] # region of interest for tracking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV Color Maping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_roi = cv2.cvtColor(roi,\n",
    "                   cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram to target on each frame for meanshift calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_hist = cv2.calcHist([hsv_roi],\n",
    "                        [0],\n",
    "                        None,\n",
    "                        [180],\n",
    "                        [0, 180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.normalize(roi_hist,\n",
    "              roi_hist,\n",
    "              0,\n",
    "              255,\n",
    "              cv2.NORM_MINMAX);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the termination criteria\n",
    "10 iterations or move 1 pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop\n",
    "while True:\n",
    "\n",
    "    # capture video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if statement\n",
    "    if ret == True:\n",
    "    \n",
    "        # Frame in hsv\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # calculate the base of ROI\n",
    "        dest_roi = cv2.calcBackProject([hsv],\n",
    "                                       [0],\n",
    "                                       roi_hist,\n",
    "                                       [0, 180],\n",
    "                                       1)\n",
    "        \n",
    "        # meanshift to get the new cordinates of rectangle\n",
    "        ret, track_window = cv2.meanShift(dest_roi,\n",
    "                                         track_window,\n",
    "                                         term_crit)\n",
    "        \n",
    "        # Draw new rectangle on image\n",
    "        x,y,w,h = track_window\n",
    "        \n",
    "        # open new window and display\n",
    "        img2 = cv2.rectangle(frame, \n",
    "                             (x,y),\n",
    "                             (x+w, y+h),\n",
    "                             (255, 255, 0),\n",
    "                             3)\n",
    "                # (255, 255, 0) is the color of the rectangle\n",
    "                # 3 is the thickness of rectangle\n",
    "        cv2.imshow('Facetracker', img2)\n",
    "        \n",
    "        # close window\n",
    "        if cv2.waitKey(50) & 0xFF == 27:  # 27 represents ESC\n",
    "            break\n",
    "        \n",
    "    # else statement\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# release and destroy\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
